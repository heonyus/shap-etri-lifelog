{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e762de",
   "metadata": {},
   "source": [
    "# SHAP 분석 노트북: ETRI Lifelog Dataset\n",
    "\n",
    "## 목적\n",
    "이 노트북은 ETRI Lifelog Dataset 2024의 Q1 예측 모델에 대한 SHAP(SHapley Additive exPlanations) 분석을 수행합니다.\n",
    "\n",
    "SHAP 분석을 통해:\n",
    "- 각 특성(feature)이 개별 예측에 어떻게 기여하는지 이해\n",
    "- 모델의 전역적(global) 특성 중요도 파악\n",
    "- 특성 간 상호작용 효과 분석\n",
    "- 개별 샘플에 대한 설명 제공\n",
    "\n",
    "## 분석 단계\n",
    "1. 환경 설정 및 데이터 로드\n",
    "2. 모델 로드 및 검증\n",
    "3. SHAP 값 계산\n",
    "4. 다양한 시각화 및 해석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29fec411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f1e151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP 버전: 0.49.1\n"
     ]
    }
   ],
   "source": [
    "# 1. 환경 설정 및 라이브러리 임포트\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP 라이브러리\n",
    "try:\n",
    "    import shap\n",
    "    print(f\"SHAP 버전: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SHAP 라이브러리가 설치되지 않았습니다. 'pip install shap' 명령으로 설치해주세요.\")\n",
    "    raise\n",
    "\n",
    "# 경로 설정\n",
    "ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name==\"notebook\" else Path.cwd()\n",
    "PROC = ROOT / \"data\" / \"processed\" / \"etrilifelog\"\n",
    "ART = ROOT / \"artifacts\"\n",
    "RAW = ROOT / \"data\" / \"raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea1928",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 탐색\n",
    "\n",
    "데이터셋의 기본 정보를 확인하고, 모델 학습에 사용된 특성과 타겟 변수를 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceb431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 크기: (450, 11)\n",
      "\n",
      "컬럼 목록:\n",
      "['subject_id', 'lifelog_date', 'sleep_date', 'dow', 'is_weekend', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
      "\n",
      "데이터 타입:\n",
      "subject_id            category\n",
      "lifelog_date    datetime64[ns]\n",
      "sleep_date      datetime64[ns]\n",
      "dow                       int8\n",
      "is_weekend                int8\n",
      "Q1                        int8\n",
      "Q2                        int8\n",
      "Q3                        int8\n",
      "S1                        int8\n",
      "S2                        int8\n",
      "S3                        int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "ds = pd.read_parquet(PROC / \"metrics_only.parquet\")\n",
    "print(f\"데이터셋 크기: {ds.shape}\")\n",
    "print(f\"\\n컬럼 목록:\")\n",
    "print(ds.columns.tolist())\n",
    "print(f\"\\n데이터 타입:\")\n",
    "print(ds.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a22767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>lifelog_date</th>\n",
       "      <th>sleep_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id lifelog_date sleep_date  dow  is_weekend  Q1  Q2  Q3  S1  S2  S3\n",
       "0       id01   2024-06-26 2024-06-27    2           0   0   0   0   0   0   1\n",
       "1       id01   2024-06-27 2024-06-28    3           0   0   0   0   0   1   1\n",
       "2       id01   2024-06-28 2024-06-29    4           0   1   0   0   1   1   1\n",
       "3       id01   2024-06-29 2024-06-30    5           1   1   0   1   2   0   0\n",
       "4       id01   2024-06-30 2024-07-01    6           1   0   1   1   1   1   1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e20ae4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "기본 통계:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifelog_date</th>\n",
       "      <th>sleep_date</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450</td>\n",
       "      <td>450</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024-08-08 14:36:48</td>\n",
       "      <td>2024-08-09 14:36:48</td>\n",
       "      <td>3.048889</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.495556</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.651111</td>\n",
       "      <td>0.662222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2024-06-03 00:00:00</td>\n",
       "      <td>2024-06-04 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2024-07-13 00:00:00</td>\n",
       "      <td>2024-07-14 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2024-08-04 00:00:00</td>\n",
       "      <td>2024-08-05 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-08-31 00:00:00</td>\n",
       "      <td>2024-09-01 00:00:00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-11-14 00:00:00</td>\n",
       "      <td>2024-11-15 00:00:00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.023759</td>\n",
       "      <td>0.458768</td>\n",
       "      <td>0.500537</td>\n",
       "      <td>0.496665</td>\n",
       "      <td>0.490443</td>\n",
       "      <td>0.696795</td>\n",
       "      <td>0.477149</td>\n",
       "      <td>0.473479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lifelog_date           sleep_date         dow  is_weekend  \\\n",
       "count                  450                  450  450.000000  450.000000   \n",
       "mean   2024-08-08 14:36:48  2024-08-09 14:36:48    3.048889    0.300000   \n",
       "min    2024-06-03 00:00:00  2024-06-04 00:00:00    0.000000    0.000000   \n",
       "25%    2024-07-13 00:00:00  2024-07-14 00:00:00    1.000000    0.000000   \n",
       "50%    2024-08-04 00:00:00  2024-08-05 00:00:00    3.000000    0.000000   \n",
       "75%    2024-08-31 00:00:00  2024-09-01 00:00:00    5.000000    1.000000   \n",
       "max    2024-11-14 00:00:00  2024-11-15 00:00:00    6.000000    1.000000   \n",
       "std                    NaN                  NaN    2.023759    0.458768   \n",
       "\n",
       "               Q1          Q2          Q3          S1          S2          S3  \n",
       "count  450.000000  450.000000  450.000000  450.000000  450.000000  450.000000  \n",
       "mean     0.495556    0.562222    0.600000    0.866667    0.651111    0.662222  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000    2.000000    1.000000    1.000000  \n",
       "std      0.500537    0.496665    0.490443    0.696795    0.477149    0.473479  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n기본 통계:\")\n",
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87dfcb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 카탈로그:\n",
      "{\n",
      "  \"dataset\": \"ETRI Lifelog 2024\",\n",
      "  \"rows\": 450,\n",
      "  \"subjects\": 10,\n",
      "  \"date_range\": {\n",
      "    \"min\": \"2024-06-03\",\n",
      "    \"max\": \"2024-11-14\"\n",
      "  },\n",
      "  \"targets\": {\n",
      "    \"Q1\": {\n",
      "      \"0\": 227,\n",
      "      \"1\": 223\n",
      "    },\n",
      "    \"Q2\": {\n",
      "      \"1\": 253,\n",
      "      \"0\": 197\n",
      "    },\n",
      "    \"Q3\": {\n",
      "      \"1\": 270,\n",
      "      \"0\": 180\n",
      "    },\n",
      "    \"S1\": {\n",
      "      \"1\": 224,\n",
      "      \"0\": 143,\n",
      "      \"2\": 83\n",
      "    },\n",
      "    \"S2\": {\n",
      "      \"1\": 293,\n",
      "      \"0\": 157\n",
      "    },\n",
      "    \"S3\": {\n",
      "      \"1\": 298,\n",
      "      \"0\": 152\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 카탈로그 정보 확인\n",
    "catalog = json.loads((ART / \"dataset_catalog.json\").read_text())\n",
    "print(\"데이터셋 카탈로그:\")\n",
    "print(json.dumps(catalog, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35ef0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "배경 샘플 크기: 450\n",
      "배경 샘플 시드: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 배경 샘플 정보 확인\n",
    "bg_info = json.loads((ART / \"background_idx.json\").read_text())\n",
    "print(f\"\\n배경 샘플 크기: {bg_info['size']}\")\n",
    "print(f\"배경 샘플 시드: {bg_info['seed']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a21fc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "기저값(phi0) 정보:\n",
      "{\n",
      "  \"link\": \"prob\",\n",
      "  \"phi0\": 0.49553997834369107\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# phi0 정보 확인\n",
    "phi0_info = json.loads((ART / \"phi0_q1.json\").read_text())\n",
    "print(f\"\\n기저값(phi0) 정보:\")\n",
    "print(json.dumps(phi0_info, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af3d58af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 변수: ['dow', 'is_weekend']\n",
      "타겟 변수: Q1\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습에 사용된 특성과 타겟 변수 추출\n",
    "feature_cols = [\"dow\", \"is_weekend\"]  # 요일(day of week), 주말 여부\n",
    "target_col = \"Q1\"\n",
    "\n",
    "X = ds[feature_cols].copy()\n",
    "y = ds[target_col].copy()\n",
    "\n",
    "print(f\"특성 변수: {feature_cols}\")\n",
    "print(f\"타겟 변수: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e0c29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "특성 변수 분포:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.048889</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.023759</td>\n",
       "      <td>0.458768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dow  is_weekend\n",
       "count  450.000000  450.000000\n",
       "mean     3.048889    0.300000\n",
       "std      2.023759    0.458768\n",
       "min      0.000000    0.000000\n",
       "25%      1.000000    0.000000\n",
       "50%      3.000000    0.000000\n",
       "75%      5.000000    1.000000\n",
       "max      6.000000    1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n특성 변수 분포:\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a82d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "타겟 변수 분포:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Q1\n",
       "0    227\n",
       "1    223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n타겟 변수 분포:\")\n",
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "004f62c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "타겟 변수 비율:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Q1\n",
       "0    0.504444\n",
       "1    0.495556\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n타겟 변수 비율:\")\n",
    "y.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4a468",
   "metadata": {},
   "source": [
    "## 2. 모델 로드 및 검증\n",
    "\n",
    "학습된 모델을 로드하고 예측 성능을 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203e4e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 타입: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "\n",
      "모델 파라미터:\n",
      "  - 클래스: [0 1]\n",
      "  - 절편(intercept): -0.114694\n",
      "  - 계수(coef): {'dow': np.float64(0.059023888854384525), 'is_weekend': np.float64(-0.2770407352538158)}\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model_path = ART / \"model_q1_logit.joblib\"\n",
    "model = joblib.load(model_path)\n",
    "print(f\"모델 타입: {type(model)}\")\n",
    "print(f\"\\n모델 파라미터:\")\n",
    "print(f\"  - 클래스: {model.classes_}\")\n",
    "print(f\"  - 절편(intercept): {model.intercept_[0]:.6f}\")\n",
    "print(f\"  - 계수(coef): {dict(zip(feature_cols, model.coef_[0]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b59d8003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 확률 통계:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    450.000000\n",
       "mean       0.495540\n",
       "std        0.019568\n",
       "min        0.471358\n",
       "25%        0.475865\n",
       "50%        0.490603\n",
       "75%        0.515589\n",
       "max        0.530313\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 예측 확인\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f\"예측 확률 통계:\")\n",
    "pd.Series(y_pred_proba).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9d51c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "예측 클래스 분포:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    260\n",
       "1    190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n예측 클래스 분포:\")\n",
    "pd.Series(y_pred).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f1ddc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "실제 클래스 분포:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Q1\n",
       "0    227\n",
       "1    223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n실제 클래스 분포:\")\n",
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1854c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 성능:\n",
      "  - 정확도: 0.5222\n",
      "  - AUROC: 0.5142\n",
      "\n",
      "혼동 행렬:\n",
      "[[136  91]\n",
      " [124  99]]\n"
     ]
    }
   ],
   "source": [
    "# 정확도 확인\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_pred_proba)\n",
    "print(f\"\\n모델 성능:\")\n",
    "print(f\"  - 정확도: {accuracy:.4f}\")\n",
    "print(f\"  - AUROC: {auc:.4f}\")\n",
    "print(f\"\\n혼동 행렬:\")\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff19a",
   "metadata": {},
   "source": [
    "## 3. SHAP 값 계산\n",
    "\n",
    "SHAP는 각 특성이 예측에 기여하는 정도를 정량화합니다. \n",
    "- **기저값(φ₀)**: 배경 분포에서의 평균 예측값\n",
    "- **SHAP 값(φᵢ)**: 각 특성이 기저값에서 얼마나 기여하는지\n",
    "\n",
    "### 3.1 배경 샘플 준비\n",
    "배경 샘플은 SHAP 계산의 기준점으로 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99bfdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배경 샘플 크기: 450\n",
      "\n",
      "배경 샘플 통계:\n",
      "              dow  is_weekend\n",
      "count  450.000000  450.000000\n",
      "mean     3.048889    0.300000\n",
      "std      2.023759    0.458768\n",
      "min      0.000000    0.000000\n",
      "25%      1.000000    0.000000\n",
      "50%      3.000000    0.000000\n",
      "75%      5.000000    1.000000\n",
      "max      6.000000    1.000000\n",
      "\n",
      "배경 샘플 특성 분포:\n",
      "\n",
      "dow:\n",
      "dow\n",
      "0    65\n",
      "1    60\n",
      "2    64\n",
      "3    65\n",
      "4    61\n",
      "5    65\n",
      "6    70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "is_weekend:\n",
      "is_weekend\n",
      "0    315\n",
      "1    135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 배경 샘플 인덱스 로드\n",
    "bg_idx = json.loads((ART / \"background_idx.json\").read_text())[\"index\"]\n",
    "X_background = X.iloc[bg_idx].copy()\n",
    "\n",
    "print(f\"배경 샘플 크기: {len(X_background)}\")\n",
    "print(f\"\\n배경 샘플 통계:\")\n",
    "print(X_background.describe())\n",
    "print(f\"\\n배경 샘플 특성 분포:\")\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(X_background[col].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "107a66f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The option feature_dependence has been renamed to feature_perturbation!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m model.predict_proba(X_input)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Linear SHAP Explainer 생성 (선형 모델에 최적화)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# LinearExplainer는 선형 모델의 SHAP 값을 정확하게 계산합니다.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m explainer_linear = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinearExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_background\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_dependence\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindependent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLinear SHAP Explainer 생성 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m특성 개수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\shap-etri-lifelog\\.venv\\Lib\\site-packages\\shap\\explainers\\_linear.py:92\u001b[39m, in \u001b[36mLinearExplainer.__init__\u001b[39m\u001b[34m(self, model, masker, link, nsamples, feature_perturbation, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfeature_dependence\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     91\u001b[39m     emsg = \u001b[33m\"\u001b[39m\u001b[33mThe option feature_dependence has been renamed to feature_perturbation!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(emsg)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_perturbation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m     95\u001b[39m     wmsg = (\n\u001b[32m     96\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe feature_perturbation option is now deprecated in favor of using the appropriate \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmasker (maskers.Independent, maskers.Partition or maskers.Impute).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The option feature_dependence has been renamed to feature_perturbation!"
     ]
    }
   ],
   "source": [
    "# 모델 래퍼 함수 정의 (확률 출력)\n",
    "def model_predict_proba(X_input):\n",
    "    \"\"\"모델 예측 함수 (확률 출력)\"\"\"\n",
    "    if isinstance(X_input, pd.DataFrame):\n",
    "        return model.predict_proba(X_input.values)[:, 1]\n",
    "    else:\n",
    "        return model.predict_proba(X_input)[:, 1]\n",
    "\n",
    "# Linear SHAP Explainer 생성 (선형 모델에 최적화)\n",
    "# LinearExplainer는 선형 모델의 SHAP 값을 정확하게 계산합니다.\n",
    "explainer_linear = shap.LinearExplainer(\n",
    "    model, \n",
    "    X_background,\n",
    ")\n",
    "\n",
    "print(\"Linear SHAP Explainer 생성 완료\")\n",
    "print(f\"특성 개수: {len(feature_cols)}\")\n",
    "print(f\"배경 샘플 크기: {len(X_background)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4206cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 phi0: 0.495540\n",
      "계산된 phi0: 0.495540\n",
      "차이: 0.0000000000\n",
      "\n",
      "해석: 배경 샘플에서 모델이 예측하는 평균 확률은 0.4955입니다.\n",
      "이는 특성 정보 없이 전체 데이터셋의 평균 예측값을 의미합니다.\n"
     ]
    }
   ],
   "source": [
    "# 기저값(phi0) 계산 및 검증\n",
    "phi0_computed = model.predict_proba(X_background)[:, 1].mean()\n",
    "phi0_stored = json.loads((ART / \"phi0_q1.json\").read_text())[\"phi0\"]\n",
    "\n",
    "print(f\"저장된 phi0: {phi0_stored:.6f}\")\n",
    "print(f\"계산된 phi0: {phi0_computed:.6f}\")\n",
    "print(f\"차이: {abs(phi0_stored - phi0_computed):.10f}\")\n",
    "\n",
    "# phi0는 배경 분포에서의 평균 예측값\n",
    "print(f\"\\n해석: 배경 샘플에서 모델이 예측하는 평균 확률은 {phi0_computed:.4f}입니다.\")\n",
    "print(f\"이는 특성 정보 없이 전체 데이터셋의 평균 예측값을 의미합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d96aa",
   "metadata": {},
   "source": [
    "### 3.2 SHAP Explainer 생성\n",
    "\n",
    "로지스틱 회귀 모델의 경우 Kernel SHAP 또는 Linear SHAP를 사용할 수 있습니다.\n",
    "- **Linear SHAP**: 선형 모델에 최적화된 빠른 방법\n",
    "- **Kernel SHAP**: 범용적이지만 상대적으로 느림\n",
    "\n",
    "우선 Linear SHAP를 사용하고, 필요시 Kernel SHAP도 비교합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83671f7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_predict_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Kernel SHAP Explainer 생성 (범용적 방법, 비교용)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# KernelExplainer는 모든 모델에 적용 가능하지만 계산 비용이 높습니다.\u001b[39;00m\n\u001b[32m      3\u001b[39m explainer_kernel = shap.KernelExplainer(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mmodel_predict_proba\u001b[49m,\n\u001b[32m      5\u001b[39m     X_background\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKernel SHAP Explainer 생성 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m참고: Kernel SHAP는 샘플링 기반이므로 계산 시간이 더 걸립니다.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_predict_proba' is not defined"
     ]
    }
   ],
   "source": [
    "# Kernel SHAP Explainer 생성 (범용적 방법, 비교용)\n",
    "# KernelExplainer는 모든 모델에 적용 가능하지만 계산 비용이 높습니다.\n",
    "explainer_kernel = shap.KernelExplainer(\n",
    "    model_predict_proba,\n",
    "    X_background\n",
    ")\n",
    "\n",
    "print(\"Kernel SHAP Explainer 생성 완료\")\n",
    "print(\"참고: Kernel SHAP는 샘플링 기반이므로 계산 시간이 더 걸립니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20979ed6",
   "metadata": {},
   "source": [
    "### 3.3 SHAP 값 계산\n",
    "\n",
    "전체 데이터셋에 대해 SHAP 값을 계산합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffff9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SHAP 값 계산 (빠른 방법)\n",
    "print(\"Linear SHAP 값 계산 중...\")\n",
    "shap_values_linear = explainer_linear.shap_values(X)\n",
    "print(f\"SHAP 값 shape: {shap_values_linear.shape}\")\n",
    "print(f\"SHAP 값 통계:\")\n",
    "print(pd.DataFrame(shap_values_linear, columns=feature_cols).describe())\n",
    "\n",
    "# SHAP 값의 합이 예측값과 일치하는지 확인 (재구성 검증)\n",
    "shap_sum = phi0_computed + shap_values_linear.sum(axis=1)\n",
    "pred_proba = model.predict_proba(X)[:, 1]\n",
    "reconstruction_error = np.abs(shap_sum - pred_proba).mean()\n",
    "print(f\"\\n재구성 오차 (MAE): {reconstruction_error:.10f}\")\n",
    "print(\"(SHAP 값의 합 + 기저값 = 예측값이어야 합니다)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SHAP 값 계산 (샘플 일부에 대해 비교용)\n",
    "# 전체 데이터셋에 대해 계산하면 시간이 오래 걸리므로, 샘플만 계산\n",
    "np.random.seed(42)  # 재현성을 위한 시드 설정\n",
    "sample_size = min(100, len(X))\n",
    "sample_idx = np.random.choice(len(X), size=sample_size, replace=False)\n",
    "X_sample = X.iloc[sample_idx]\n",
    "\n",
    "print(f\"Kernel SHAP 값 계산 중... (샘플 크기: {sample_size})\")\n",
    "print(\"주의: Kernel SHAP는 순열 샘플링을 사용하므로 시간이 걸립니다.\")\n",
    "shap_values_kernel = explainer_kernel.shap_values(X_sample, nsamples=100)\n",
    "\n",
    "print(f\"Kernel SHAP 값 shape: {shap_values_kernel.shape}\")\n",
    "print(f\"Kernel SHAP 값 통계:\")\n",
    "print(pd.DataFrame(shap_values_kernel, columns=feature_cols).describe())\n",
    "\n",
    "# Linear와 Kernel SHAP 비교\n",
    "print(f\"\\nLinear vs Kernel SHAP 비교 (샘플 {sample_size}개):\")\n",
    "linear_sample = shap_values_linear[sample_idx]\n",
    "kernel_sample = shap_values_kernel\n",
    "for i, col in enumerate(feature_cols):\n",
    "    corr = np.corrcoef(linear_sample[:, i], kernel_sample[:, i])[0, 1]\n",
    "    mae = np.abs(linear_sample[:, i] - kernel_sample[:, i]).mean()\n",
    "    print(f\"  {col}: 상관계수={corr:.4f}, MAE={mae:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59d533",
   "metadata": {},
   "source": [
    "## 4. SHAP 시각화 및 해석\n",
    "\n",
    "SHAP 값을 다양한 방식으로 시각화하여 모델의 예측을 해석합니다.\n",
    "\n",
    "### 4.1 Summary Plot (전역 특성 중요도)\n",
    "\n",
    "Summary Plot은 모든 샘플에서 각 특성의 SHAP 값 분포를 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ef26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Plot 생성\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(\n",
    "    shap_values_linear, \n",
    "    X, \n",
    "    feature_names=feature_cols,\n",
    "    show=False,\n",
    "    plot_type=\"bar\"  # 막대 그래프 형태\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot (Bar) - 전역 특성 중요도\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n해석:\")\n",
    "print(\"- 각 막대의 길이는 평균 |SHAP 값|을 나타냅니다.\")\n",
    "print(\"- 특성이 예측에 미치는 영향의 크기를 비교할 수 있습니다.\")\n",
    "print(\"- 값이 클수록 해당 특성이 예측에 더 중요합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb15ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Plot (점 그래프 형태) - 특성 값과 SHAP 값의 관계\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(\n",
    "    shap_values_linear, \n",
    "    X, \n",
    "    feature_names=feature_cols,\n",
    "    show=False,\n",
    "    plot_type=\"dot\"  # 점 그래프 형태\n",
    ")\n",
    "plt.title(\"SHAP Summary Plot (Dot) - 특성 값과 SHAP 값의 관계\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n해석:\")\n",
    "print(\"- 각 점은 하나의 샘플을 나타냅니다.\")\n",
    "print(\"- X축: SHAP 값 (특성의 기여도)\")\n",
    "print(\"- Y축: 특성 이름 (중요도 순으로 정렬)\")\n",
    "print(\"- 색상: 특성 값 (빨강=높은 값, 파랑=낮은 값)\")\n",
    "print(\"- 특성 값이 높을 때 SHAP 값이 양수면, 해당 특성이 예측을 증가시키는 방향으로 작용합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28265ef3",
   "metadata": {},
   "source": [
    "### 4.2 Waterfall Plot (개별 샘플 설명)\n",
    "\n",
    "Waterfall Plot은 특정 샘플 하나에 대해 SHAP 값이 어떻게 누적되어 예측값을 만드는지 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341da7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 가지 대표적인 샘플 선택\n",
    "# 1. 높은 확률 예측 샘플\n",
    "high_prob_idx = np.argmax(y_pred_proba)\n",
    "# 2. 낮은 확률 예측 샘플\n",
    "low_prob_idx = np.argmin(y_pred_proba)\n",
    "# 3. 중간 확률 예측 샘플\n",
    "mid_prob_idx = np.argmin(np.abs(y_pred_proba - 0.5))\n",
    "\n",
    "sample_indices = [high_prob_idx, mid_prob_idx, low_prob_idx]\n",
    "sample_labels = [\"높은 확률 예측\", \"중간 확률 예측\", \"낮은 확률 예측\"]\n",
    "\n",
    "for idx, label in zip(sample_indices, sample_labels):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"샘플 #{idx}: {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"실제 특성 값:\")\n",
    "    print(X.iloc[idx])\n",
    "    print(f\"\\n실제 예측 확률: {y_pred_proba[idx]:.4f}\")\n",
    "    print(f\"실제 타겟: {y.iloc[idx]}\")\n",
    "    print(f\"\\nSHAP 값:\")\n",
    "    for i, col in enumerate(feature_cols):\n",
    "        print(f\"  {col}: {shap_values_linear[idx, i]:.6f}\")\n",
    "    print(f\"기저값(phi0): {phi0_computed:.6f}\")\n",
    "    print(f\"검증: {phi0_computed + shap_values_linear[idx].sum():.6f} ≈ {y_pred_proba[idx]:.6f}\")\n",
    "    \n",
    "    # Waterfall Plot 생성\n",
    "    shap_explanation = shap.Explanation(\n",
    "        values=shap_values_linear[idx:idx+1],\n",
    "        base_values=np.array([phi0_computed]),\n",
    "        data=X.iloc[idx:idx+1].values,\n",
    "        feature_names=feature_cols\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.waterfall_plot(shap_explanation[0], show=False)\n",
    "    plt.title(f\"Waterfall Plot - 샘플 #{idx} ({label})\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318b9a5",
   "metadata": {},
   "source": [
    "### 4.3 Force Plot (개별 샘플 힘 플롯)\n",
    "\n",
    "Force Plot은 각 특성이 예측값을 얼마나 증가/감소시키는지 시각적으로 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Plot 생성 (HTML 출력)\n",
    "# 여러 샘플에 대해 생성\n",
    "for idx, label in zip(sample_indices[:3], sample_labels[:3]):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"샘플 #{idx}: {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    shap_explanation = shap.Explanation(\n",
    "        values=shap_values_linear[idx:idx+1],\n",
    "        base_values=np.array([phi0_computed]),\n",
    "        data=X.iloc[idx:idx+1].values,\n",
    "        feature_names=feature_cols\n",
    "    )\n",
    "    \n",
    "    # Force Plot (HTML)\n",
    "    shap.force_plot(\n",
    "        phi0_computed,\n",
    "        shap_values_linear[idx],\n",
    "        X.iloc[idx],\n",
    "        feature_names=feature_cols,\n",
    "        matplotlib=True  # matplotlib 버전 사용\n",
    "    )\n",
    "    plt.title(f\"Force Plot - 샘플 #{idx} ({label})\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n해석:\")\n",
    "    print(\"- 빨간색: 예측을 증가시키는 특성 (양의 SHAP 값)\")\n",
    "    print(\"- 파란색: 예측을 감소시키는 특성 (음의 SHAP 값)\")\n",
    "    print(\"- 막대 길이: SHAP 값의 크기 (기여도)\")\n",
    "    print(\"- 최종 예측값 = 기저값 + 빨간색 기여 - 파란색 기여\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc1648",
   "metadata": {},
   "source": [
    "### 4.4 Dependence Plot (특성 간 상호작용)\n",
    "\n",
    "Dependence Plot은 특정 특성의 값에 따른 SHAP 값의 변화를 보여주며, 다른 특성과의 상호작용도 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eef5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 특성에 대한 Dependence Plot 생성\n",
    "for i, feature_name in enumerate(feature_cols):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"특성: {feature_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 다른 특성을 interaction feature로 사용\n",
    "    interaction_feature = feature_cols[1-i] if len(feature_cols) > 1 else None\n",
    "    \n",
    "    shap.dependence_plot(\n",
    "        i,\n",
    "        shap_values_linear,\n",
    "        X,\n",
    "        feature_names=feature_cols,\n",
    "        interaction_index=interaction_feature,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"Dependence Plot - {feature_name}\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n해석:\")\n",
    "    print(f\"- X축: {feature_name}의 실제 값\")\n",
    "    print(f\"- Y축: {feature_name}의 SHAP 값\")\n",
    "    print(f\"- 색상: {interaction_feature}의 값 (상호작용 특성)\")\n",
    "    print(f\"- 곡선의 형태를 통해 {feature_name}이 예측에 미치는 영향을 확인할 수 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366e21b",
   "metadata": {},
   "source": [
    "### 4.5 부분 의존성 분석 (Partial Dependence)\n",
    "\n",
    "특성 값의 변화에 따른 예측값의 변화를 직접 확인합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 특성에 대한 부분 의존성 플롯\n",
    "fig, axes = plt.subplots(1, len(feature_cols), figsize=(15, 5))\n",
    "if len(feature_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(feature_cols, axes)):\n",
    "    # 특성 값의 고유값 정렬\n",
    "    unique_vals = sorted(X[col].unique())\n",
    "    \n",
    "    # 각 값에 대해 평균 예측값 계산\n",
    "    pdp_values = []\n",
    "    for val in unique_vals:\n",
    "        X_temp = X_background.copy()\n",
    "        X_temp[col] = val\n",
    "        preds = model.predict_proba(X_temp)[:, 1]\n",
    "        pdp_values.append(preds.mean())\n",
    "    \n",
    "    # 플롯 생성\n",
    "    ax.plot(unique_vals, pdp_values, marker='o', linewidth=2, markersize=8)\n",
    "    ax.set_xlabel(col, fontsize=12)\n",
    "    ax.set_ylabel('평균 예측 확률', fontsize=12)\n",
    "    ax.set_title(f'Partial Dependence Plot - {col}', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=phi0_computed, color='r', linestyle='--', \n",
    "               label=f'기저값 ({phi0_computed:.4f})', alpha=0.7)\n",
    "    ax.legend()\n",
    "    \n",
    "    print(f\"\\n{col} 부분 의존성:\")\n",
    "    for val, pred in zip(unique_vals, pdp_values):\n",
    "        print(f\"  {col}={val}: 평균 예측={pred:.4f} (기저값 대비 {pred-phi0_computed:+.4f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570740e",
   "metadata": {},
   "source": [
    "### 4.6 특성별 SHAP 값 분포 상세 분석\n",
    "\n",
    "각 특성의 SHAP 값 분포를 통계적으로 분석합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 값을 DataFrame으로 변환\n",
    "shap_df = pd.DataFrame(shap_values_linear, columns=feature_cols)\n",
    "shap_df['predicted_proba'] = y_pred_proba\n",
    "shap_df['actual'] = y.values\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SHAP 값 통계 요약\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  평균 SHAP 값: {shap_df[col].mean():.6f}\")\n",
    "    print(f\"  표준편차: {shap_df[col].std():.6f}\")\n",
    "    print(f\"  최소값: {shap_df[col].min():.6f}\")\n",
    "    print(f\"  최대값: {shap_df[col].max():.6f}\")\n",
    "    print(f\"  평균 절대값: {np.abs(shap_df[col]).mean():.6f}\")\n",
    "    print(f\"  중앙값: {shap_df[col].median():.6f}\")\n",
    "\n",
    "# 특성별 SHAP 값 분포 시각화\n",
    "fig, axes = plt.subplots(1, len(feature_cols), figsize=(15, 5))\n",
    "if len(feature_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(feature_cols, axes)):\n",
    "    ax.hist(shap_df[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='SHAP=0')\n",
    "    ax.axvline(x=shap_df[col].mean(), color='g', linestyle='--', linewidth=2, \n",
    "               label=f'평균={shap_df[col].mean():.4f}')\n",
    "    ax.set_xlabel('SHAP 값', fontsize=12)\n",
    "    ax.set_ylabel('빈도', fontsize=12)\n",
    "    ax.set_title(f'{col} SHAP 값 분포', fontsize=13, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cc373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 값별 평균 SHAP 값 분석\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"특성 값별 평균 SHAP 값 분석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}에 따른 SHAP 값:\")\n",
    "    grouped = shap_df.groupby(X[col])[col].agg(['mean', 'std', 'count'])\n",
    "    grouped.columns = ['평균_SHAP', '표준편차', '샘플수']\n",
    "    print(grouped)\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    unique_vals = sorted(X[col].unique())\n",
    "    mean_shaps = [shap_df[X[col] == val][col].mean() for val in unique_vals]\n",
    "    std_shaps = [shap_df[X[col] == val][col].std() for val in unique_vals]\n",
    "    \n",
    "    plt.bar(unique_vals, mean_shaps, yerr=std_shaps, capsize=5, \n",
    "            edgecolor='black', alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel('평균 SHAP 값', fontsize=12)\n",
    "    plt.title(f'{col} 값별 평균 SHAP 값', fontsize=13, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf2788",
   "metadata": {},
   "source": [
    "### 4.7 예측 성능 구간별 SHAP 값 분석\n",
    "\n",
    "예측 확률이 높은 샘플과 낮은 샘플에서 특성의 기여도가 어떻게 다른지 분석합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 구간별 분류\n",
    "bins = [0, 0.3, 0.5, 0.7, 1.0]\n",
    "labels = ['낮음 (0-0.3)', '중간-낮음 (0.3-0.5)', '중간-높음 (0.5-0.7)', '높음 (0.7-1.0)']\n",
    "shap_df['prob_bin'] = pd.cut(y_pred_proba, bins=bins, labels=labels)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"예측 확률 구간별 SHAP 값 분석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}의 구간별 평균 SHAP 값:\")\n",
    "    grouped = shap_df.groupby('prob_bin')[col].agg(['mean', 'std', 'count'])\n",
    "    grouped.columns = ['평균_SHAP', '표준편차', '샘플수']\n",
    "    print(grouped)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, len(feature_cols), figsize=(15, 5))\n",
    "if len(feature_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(feature_cols, axes)):\n",
    "    grouped = shap_df.groupby('prob_bin')[col].agg(['mean', 'std'])\n",
    "    x_pos = np.arange(len(grouped.index))\n",
    "    \n",
    "    ax.bar(x_pos, grouped['mean'], yerr=grouped['std'], capsize=5,\n",
    "           edgecolor='black', alpha=0.7)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(grouped.index, rotation=45, ha='right')\n",
    "    ax.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    ax.set_ylabel('평균 SHAP 값', fontsize=12)\n",
    "    ax.set_title(f'{col} - 예측 확률 구간별 SHAP 값', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81e3fa",
   "metadata": {},
   "source": [
    "### 4.8 실제 타겟 클래스별 SHAP 값 비교\n",
    "\n",
    "실제로 Q1=1인 샘플과 Q1=0인 샘플에서 특성의 기여도가 어떻게 다른지 비교합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"실제 타겟 클래스별 SHAP 값 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    grouped = shap_df.groupby('actual')[col].agg(['mean', 'std', 'count'])\n",
    "    grouped.columns = ['평균_SHAP', '표준편차', '샘플수']\n",
    "    print(grouped)\n",
    "    \n",
    "    # 통계적 유의성 검정 (t-test)\n",
    "    from scipy import stats\n",
    "    q1_0_shap = shap_df[shap_df['actual'] == 0][col]\n",
    "    q1_1_shap = shap_df[shap_df['actual'] == 1][col]\n",
    "    t_stat, p_value = stats.ttest_ind(q1_0_shap, q1_1_shap)\n",
    "    print(f\"  t-검정: t={t_stat:.4f}, p={p_value:.6f}\")\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, len(feature_cols), figsize=(15, 5))\n",
    "if len(feature_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(feature_cols, axes)):\n",
    "    q1_0_shap = shap_df[shap_df['actual'] == 0][col]\n",
    "    q1_1_shap = shap_df[shap_df['actual'] == 1][col]\n",
    "    \n",
    "    ax.hist(q1_0_shap, bins=30, alpha=0.6, label='Q1=0', color='blue', edgecolor='black')\n",
    "    ax.hist(q1_1_shap, bins=30, alpha=0.6, label='Q1=1', color='red', edgecolor='black')\n",
    "    ax.axvline(x=q1_0_shap.mean(), color='blue', linestyle='--', linewidth=2, \n",
    "               label=f'Q1=0 평균 ({q1_0_shap.mean():.4f})')\n",
    "    ax.axvline(x=q1_1_shap.mean(), color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Q1=1 평균 ({q1_1_shap.mean():.4f})')\n",
    "    ax.axvline(x=0, color='black', linestyle=':', linewidth=1)\n",
    "    ax.set_xlabel('SHAP 값', fontsize=12)\n",
    "    ax.set_ylabel('빈도', fontsize=12)\n",
    "    ax.set_title(f'{col} - 클래스별 SHAP 값 분포', fontsize=13, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e5dfb",
   "metadata": {},
   "source": [
    "### 4.9 특성 간 상관관계 및 SHAP 값 상관관계\n",
    "\n",
    "특성 간의 상관관계와 SHAP 값 간의 상관관계를 비교합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07635f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 간 상관관계\n",
    "print(\"=\"*60)\n",
    "print(\"특성 간 상관관계\")\n",
    "print(\"=\"*60)\n",
    "feature_corr = X[feature_cols].corr()\n",
    "print(feature_corr)\n",
    "\n",
    "# SHAP 값 간 상관관계\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SHAP 값 간 상관관계\")\n",
    "print(\"=\"*60)\n",
    "shap_corr = shap_df[feature_cols].corr()\n",
    "print(shap_corr)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 특성 상관관계 히트맵\n",
    "sns.heatmap(feature_corr, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=axes[0], cbar_kws={'label': '상관계수'})\n",
    "axes[0].set_title('특성 간 상관관계', fontsize=13, fontweight='bold')\n",
    "\n",
    "# SHAP 값 상관관계 히트맵\n",
    "sns.heatmap(shap_corr, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=axes[1], cbar_kws={'label': '상관계수'})\n",
    "axes[1].set_title('SHAP 값 간 상관관계', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n해석:\")\n",
    "print(\"- 특성 간 상관관계가 높으면, 모델이 특성들을 함께 고려할 수 있습니다.\")\n",
    "print(\"- SHAP 값 간 상관관계는 특성들이 예측에 미치는 영향이 함께 변하는 정도를 나타냅니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b885c",
   "metadata": {},
   "source": [
    "## 5. 종합 분석 및 해석\n",
    "\n",
    "### 5.1 전역 특성 중요도 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 특성 중요도 계산 (평균 절대 SHAP 값)\n",
    "global_importance = {}\n",
    "for col in feature_cols:\n",
    "    global_importance[col] = np.abs(shap_df[col]).mean()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"전역 특성 중요도 (평균 |SHAP 값|)\")\n",
    "print(\"=\"*60)\n",
    "importance_df = pd.DataFrame([\n",
    "    {'특성': k, '중요도': v, '비율': v/sum(global_importance.values())}\n",
    "    for k, v in sorted(global_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_features = sorted(global_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "features, importances = zip(*sorted_features)\n",
    "plt.barh(features, importances, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('평균 |SHAP 값|', fontsize=12)\n",
    "plt.ylabel('특성', fontsize=12)\n",
    "plt.title('전역 특성 중요도', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231b8ab",
   "metadata": {},
   "source": [
    "### 5.2 모델 예측 메커니즘 해석\n",
    "\n",
    "모델의 예측 메커니즘을 SHAP 값을 기반으로 해석합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"모델 예측 메커니즘 해석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in feature_cols:\n",
    "    # 특성 값별 평균 SHAP 값과 평균 예측값\n",
    "    unique_vals = sorted(X[col].unique())\n",
    "    print(f\"\\n{col} 분석:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for val in unique_vals:\n",
    "        mask = X[col] == val\n",
    "        mean_shap = shap_df[mask][col].mean()\n",
    "        mean_pred = shap_df[mask]['predicted_proba'].mean()\n",
    "        count = mask.sum()\n",
    "        \n",
    "        direction = \"증가\" if mean_shap > 0 else \"감소\" if mean_shap < 0 else \"무영향\"\n",
    "        print(f\"  {col}={val}:\")\n",
    "        print(f\"    - 샘플 수: {count}\")\n",
    "        print(f\"    - 평균 SHAP 값: {mean_shap:+.6f} ({direction})\")\n",
    "        print(f\"    - 평균 예측 확률: {mean_pred:.4f}\")\n",
    "        print(f\"    - 기저값 대비 변화: {mean_pred - phi0_computed:+.4f}\")\n",
    "\n",
    "# 모델 계수와 SHAP 값의 관계 검증\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"모델 계수와 SHAP 값의 관계\")\n",
    "print(\"=\"*60)\n",
    "print(\"로지스틱 회귀 모델의 경우, SHAP 값은 특성 값과 모델 계수의 곱과 유사합니다.\")\n",
    "print(f\"\\n모델 계수:\")\n",
    "for i, col in enumerate(feature_cols):\n",
    "    coef = model.coef_[0][i]\n",
    "    print(f\"  {col}: {coef:.6f}\")\n",
    "\n",
    "print(f\"\\n특성 값 × 계수 vs SHAP 값 비교:\")\n",
    "for col in feature_cols:\n",
    "    feature_idx = feature_cols.index(col)\n",
    "    coef = model.coef_[0][feature_idx]\n",
    "    coef_effect = X[col] * coef\n",
    "    shap_vals = shap_df[col]\n",
    "    \n",
    "    # 상관관계 확인\n",
    "    corr = np.corrcoef(coef_effect, shap_vals)[0, 1]\n",
    "    print(f\"  {col}: 상관계수 = {corr:.6f}\")\n",
    "    print(f\"    (특성 값 × 계수와 SHAP 값의 관계)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a74e1",
   "metadata": {},
   "source": [
    "### 5.3 SHAP 값의 재구성 정확성 검증\n",
    "\n",
    "SHAP 값의 합과 기저값이 실제 예측값과 일치하는지 검증합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8911622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재구성 검증\n",
    "shap_sum = shap_values_linear.sum(axis=1)\n",
    "reconstructed = phi0_computed + shap_sum\n",
    "actual_pred = y_pred_proba\n",
    "\n",
    "# 오차 계산\n",
    "errors = np.abs(reconstructed - actual_pred)\n",
    "mae = errors.mean()\n",
    "rmse = np.sqrt(np.mean(errors**2))\n",
    "max_error = errors.max()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SHAP 값 재구성 정확성 검증\")\n",
    "print(\"=\"*60)\n",
    "print(f\"기저값(phi0): {phi0_computed:.6f}\")\n",
    "print(f\"재구성 공식: 예측값 = phi0 + Σ(SHAP 값)\")\n",
    "print(f\"\\n오차 통계:\")\n",
    "print(f\"  - 평균 절대 오차 (MAE): {mae:.10f}\")\n",
    "print(f\"  - 평균 제곱근 오차 (RMSE): {rmse:.10f}\")\n",
    "print(f\"  - 최대 오차: {max_error:.10f}\")\n",
    "print(f\"  - 오차 < 1e-6인 샘플 비율: {(errors < 1e-6).mean()*100:.2f}%\")\n",
    "print(f\"  - 오차 < 1e-4인 샘플 비율: {(errors < 1e-4).mean()*100:.2f}%\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual_pred, reconstructed, alpha=0.5, s=20)\n",
    "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='완벽한 재구성 (y=x)')\n",
    "plt.xlabel('실제 예측 확률', fontsize=12)\n",
    "plt.ylabel('재구성된 예측 확률 (phi0 + ΣSHAP)', fontsize=12)\n",
    "plt.title('SHAP 값 재구성 정확성 검증', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if mae < 1e-6:\n",
    "    print(\"\\n✓ 재구성 오차가 매우 낮습니다. SHAP 값 계산이 정확합니다.\")\n",
    "else:\n",
    "    print(f\"\\n⚠ 재구성 오차가 {mae:.10f}입니다. (일반적으로 1e-6 이하가 이상적)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eafe341",
   "metadata": {},
   "source": [
    "## 6. 결론 및 요약\n",
    "\n",
    "SHAP 분석을 통해 모델의 예측 메커니즘을 해석하고, 각 특성의 기여도를 정량화했습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f993a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SHAP 분석 종합 요약\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. 데이터셋 정보:\")\n",
    "print(f\"   - 총 샘플 수: {len(X)}\")\n",
    "print(f\"   - 특성 수: {len(feature_cols)}\")\n",
    "print(f\"   - 특성: {', '.join(feature_cols)}\")\n",
    "print(f\"   - 타겟 변수: {target_col}\")\n",
    "\n",
    "print(\"\\n2. 모델 정보:\")\n",
    "print(f\"   - 모델 타입: {type(model).__name__}\")\n",
    "print(f\"   - 예측 성능 (AUROC): {auc:.4f}\")\n",
    "\n",
    "print(\"\\n3. SHAP 분석:\")\n",
    "print(f\"   - 기저값(phi0): {phi0_computed:.6f}\")\n",
    "print(f\"   - 배경 샘플 크기: {len(X_background)}\")\n",
    "print(f\"   - 재구성 오차 (MAE): {mae:.10f}\")\n",
    "\n",
    "print(\"\\n4. 전역 특성 중요도:\")\n",
    "for col in feature_cols:\n",
    "    importance = global_importance[col]\n",
    "    print(f\"   - {col}: {importance:.6f} ({importance/sum(global_importance.values())*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n5. 주요 발견:\")\n",
    "print(\"   - SHAP 값은 각 특성이 개별 예측에 기여하는 정도를 정량화합니다.\")\n",
    "print(\"   - 특성 값에 따라 SHAP 값이 달라지며, 이는 모델의 비선형성을 반영합니다.\")\n",
    "print(\"   - 재구성 검증을 통해 SHAP 값의 정확성을 확인했습니다.\")\n",
    "\n",
    "print(\"\\n6. 활용 방법:\")\n",
    "print(\"   - 개별 샘플에 대한 설명: Waterfall Plot, Force Plot\")\n",
    "print(\"   - 전역 특성 중요도: Summary Plot\")\n",
    "print(\"   - 특성 간 상호작용: Dependence Plot\")\n",
    "print(\"   - 클래스별 특성 기여도 비교: 클래스별 분포 분석\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"분석 완료!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 래퍼 함수 정의 (확률 출력)\n",
    "def model_predict_proba(X_input):\n",
    "    \"\"\"모델 예측 함수 (확률 출력)\"\"\"\n",
    "    if isinstance(X_input, pd.DataFrame):\n",
    "        return model.predict_proba(X_input.values)[:, 1]\n",
    "    else:\n",
    "        return model.predict_proba(X_input)[:, 1]\n",
    "\n",
    "# Linear SHAP Explainer 생성 (선형 모델에 최적화)\n",
    "# LinearExplainer는 선형 모델의 SHAP 값을 정확하게 계산합니다.\n",
    "explainer_linear = shap.LinearExplainer(\n",
    "    model, \n",
    "    X_background,\n",
    ")\n",
    "\n",
    "print(\"Linear SHAP Explainer 생성 완료\")\n",
    "print(f\"특성 개수: {len(feature_cols)}\")\n",
    "print(f\"배경 샘플 크기: {len(X_background)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}